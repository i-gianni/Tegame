{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71e49d21-3970-4599-b1af-e88faeee13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')\n",
    "from tegame import Tegame,is_empty_lists\n",
    "from encode import generate_all_possible_features\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc70f656-365c-41a2-b17e-1be4ac57e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_log(playcard_logs, log, include_only_combo=False):\n",
    "    \"\"\"\n",
    "    Append a single log entry to the list of playcard logs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    playcard_logs : list\n",
    "        The list that accumulates all log entries.\n",
    "\n",
    "    log : dict\n",
    "        A single log entry produced during gameplay.\n",
    "\n",
    "    include_only_combo : bool, default=False\n",
    "        If True, only logs where log['is_combo'] == True are kept.\n",
    "        If False, all logs are appended.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    deepcopy(log) is used to avoid accidental mutation of the original\n",
    "    log dictionary later in the pipeline.\n",
    "    \"\"\"\n",
    "    if include_only_combo and log['is_combo']:\n",
    "        playcard_logs.append(deepcopy(log))\n",
    "    elif include_only_combo and not log['is_combo']:\n",
    "        # Skip non-combo logs when filtering is active\n",
    "        pass\n",
    "    else:\n",
    "        # Default behavior: append everything\n",
    "        playcard_logs.append(deepcopy(log))\n",
    "\n",
    "    return playcard_logs\n",
    "\n",
    "\n",
    "def append_logs(playcard_logs, log, include_only_combo=False):\n",
    "    \"\"\"\n",
    "    Append one or multiple log entries to the playcard log list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    playcard_logs : list\n",
    "        The list that accumulates all log entries.\n",
    "\n",
    "    log : dict or list of dict\n",
    "        A single log entry or a list of log entries.\n",
    "\n",
    "    include_only_combo : bool, default=False\n",
    "        Passed through to append_log() to control filtering.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function normalizes the input so that both single logs and\n",
    "    lists of logs are handled uniformly.\n",
    "    \"\"\"\n",
    "    if log is None:\n",
    "        return\n",
    "\n",
    "    # Ensure we always iterate over a list\n",
    "    if not isinstance(log, list):\n",
    "        log = [log]\n",
    "\n",
    "    for entry in log:\n",
    "        playcard_logs = append_log(\n",
    "            playcard_logs,\n",
    "            entry,\n",
    "            include_only_combo=include_only_combo\n",
    "        )\n",
    "\n",
    "    return playcard_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24afa1b4-89ed-4041-a44c-1d6cce4825fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_games=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2bd93f-d209-4b69-b44b-7f9ecede8a14",
   "metadata": {},
   "source": [
    "**Note:** The choice of threshold parameters here is not critical.  \n",
    "> As shown in *statistical_analysis/variance_is_all_about_deck_shuffle_rather_than_thresholds.ipynb* and confirmed again in *statistical_analysis/different_thresholds_same_deck_shuffles_result_in_constant_rate.ipynb*, almost all variance in win rate comes from the deck shuffle, not from the thresholds.  \n",
    "> For this reason we simply fix the thresholds and focus on generating many independent games for the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffbcaf0f-e689-4981-8fb8-2730375efbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 49.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 117.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 118.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 128.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset: one entry per play_card call\n",
    "playcard_logs = []\n",
    "\n",
    "# we run 20 games where all moves are put in the training set,\n",
    "# while we run 20x4=80 games where only the combos are used in the training set\n",
    "# here I'm talking about combos like: 1->21->11 (in ascending piles) and 100->81->91 (in descending piles)\n",
    "\n",
    "for include_only_combo in [False,True,True,True]:\n",
    "    for i in tqdm(range(n_games)):\n",
    "        tegame_obj = Tegame(\n",
    "            verb_lvl=0,\n",
    "            thresh_nonmandatory=2,\n",
    "            thresh_secondchoice=4,\n",
    "            train_mode=True,\n",
    "            players=2\n",
    "        )\n",
    "        \n",
    "        tegame_obj.restart()\n",
    "        \n",
    "        \n",
    "        while tegame_obj.game_ongoing:\n",
    "            for active_player in range(tegame_obj.n_players):\n",
    "        \n",
    "                # Stop if all hands are empty\n",
    "                if is_empty_lists(tegame_obj.hands):\n",
    "                    tegame_obj.game_ongoing = False\n",
    "                    break\n",
    "        \n",
    "                # Sort hand (as in original logic)\n",
    "                tegame_obj.hands[active_player].sort()\n",
    "                if tegame_obj.verb_lvl>=2: tegame_obj.print_stat_hands()\n",
    "        \n",
    "                # -------------------------\n",
    "                # Mandatory moves\n",
    "                # -------------------------\n",
    "                for _ in range(tegame_obj.n_mandatory_moves):\n",
    "                    logs = tegame_obj.play_card(active_player)\n",
    "                    append_logs(playcard_logs, logs,include_only_combo=include_only_combo)\n",
    "        \n",
    "                    if tegame_obj.game_over: break\n",
    "        \n",
    "                if tegame_obj.game_over: break\n",
    "        \n",
    "                n_played = tegame_obj.n_mandatory_moves\n",
    "        \n",
    "                # -------------------------\n",
    "                # Non-mandatory moves\n",
    "                # -------------------------\n",
    "                while not tegame_obj.hands[active_player]==[]:\n",
    "                    \n",
    "                    hand_old = tegame_obj.hands[active_player].copy()\n",
    "        \n",
    "                    logs = tegame_obj.play_card(active_player, mandatory_move=False)\n",
    "        \n",
    "                    append_logs(playcard_logs, logs,include_only_combo=include_only_combo)\n",
    "        \n",
    "                    # Stop if no card was played\n",
    "                    if tegame_obj.hands[active_player] == hand_old: break\n",
    "        \n",
    "                    n_played += 1\n",
    "        \n",
    "                # -------------------------\n",
    "                # Draw cards\n",
    "                # -------------------------\n",
    "                for _ in range(n_played):\n",
    "                    tegame_obj.draw_one(active_player)\n",
    "        \n",
    "                if tegame_obj.verb_lvl>=2: tegame_obj.print_stat_piles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3997335d-5b8c-4d4b-b7c0-131072e3ad48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mandatory_moves: 1779/3108\n"
     ]
    }
   ],
   "source": [
    "# We examine the training set: how many mandatory moves?\n",
    "mandatory_move_count=0\n",
    "for log in playcard_logs:\n",
    "    hand,piles,mandatory_move,played,piles_to_avoid,is_combo = log.values()\n",
    "    if mandatory_move: mandatory_move_count+=1\n",
    "print(f'mandatory_moves: {mandatory_move_count}/{len(playcard_logs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40efe5ad-b729-43f5-93af-25eec1ff374e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_combo: 726/3108\n"
     ]
    }
   ],
   "source": [
    "# We examine the training set: how many combos?\n",
    "n_combo = 0\n",
    "for log in playcard_logs:\n",
    "    hand,piles,mandatory_move,played,piles_to_avoid,is_combo = log.values()\n",
    "    if is_combo: n_combo += 1\n",
    "print(f'n_combo: {n_combo}/{len(playcard_logs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acdec780-096d-456f-a163-280e07b20ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we convert each logged game state into a training group.\n",
    "#\n",
    "# For every turn, the environment produces:\n",
    "#   - the player's hand\n",
    "#   - the current piles\n",
    "#   - whether the move is mandatory\n",
    "#   - the actual move played (card index, pile index)\n",
    "#   - the piles to avoid (strategic constraint)\n",
    "#\n",
    "# From this information we build a *group* of training samples:\n",
    "#\n",
    "#   X_group : a tensor containing all possible (card, pile) actions\n",
    "#             encoded as feature vectors for that specific turn.\n",
    "#\n",
    "#   y_group : the index of the action actually chosen by the agent\n",
    "#             within the list of all possible actions.\n",
    "#\n",
    "# Why groups?\n",
    "# -----------\n",
    "# Each turn has a different number of legal actions, so we cannot\n",
    "# flatten everything into a single global dataset. Instead, we treat\n",
    "# each turn as a separate classification problem:\n",
    "#\n",
    "#     \"Given these features, which action was chosen?\"\n",
    "#\n",
    "# During training, the model receives X_group and must assign the\n",
    "# highest probability to the correct action y_group. This structure\n",
    "# allows the network to learn the agent's policy directly from\n",
    "# logged gameplay, even when the number of available actions varies\n",
    "# from turn to turn.\n",
    "\n",
    "groups = []\n",
    "\n",
    "for log in playcard_logs:\n",
    "    hand, piles, mandatory_move, played, piles_to_avoid, _ = log.values()\n",
    "\n",
    "    # Build X_group\n",
    "    features = generate_all_possible_features(hand, piles, mandatory_move, piles_to_avoid)\n",
    "    X_group = torch.tensor(features, dtype=torch.float32)\n",
    "    \n",
    "    # Compute y_group outside the feature generator\n",
    "    played_card_idx, played_pile_idx = played\n",
    "\n",
    "    if played_card_idx is None:\n",
    "        # NOOP is the final move\n",
    "        y_group = X_group.shape[0] - 1\n",
    "    else:\n",
    "        # actual move\n",
    "        y_group = played_card_idx * len(piles) + played_pile_idx\n",
    "\n",
    "    groups.append((X_group, y_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f41946-d8b2-4f23-b755-fb569f7a456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the traning set for subsequent training\n",
    "torch.save(groups, \"training_set.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff7305-cbf0-4192-808e-31988d6c17e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
